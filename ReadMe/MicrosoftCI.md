# Machine Learning-Driven Test Prioritization in Microsoft’s CI Pipelines

## Introduction 
Continuous Integration (CI) at Microsoft often involves running thousands of tests for each code change, which can dramatically slow down the feedback loop. In large products (e.g. Office 365), a single commit may trigger ~3000 tests, and full test suites can take **many hours** to complete – some commits have taken up to **30 hours** of testing before deployment ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=tests%20per%20test,a%20commit%20can%20be%20large)). Yet the vast majority of these tests almost always pass (e.g. 99.7% pass rate) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=tests%20per%20test,a%20commit%20can%20be%20large)), indicating a huge opportunity to skip or reorder tests that are unlikely to fail. To accelerate CI and reduce developer wait times, Microsoft has turned to **machine learning (ML)** techniques to intelligently prioritize and select tests. By learning from past test outcomes and code changes, these ML-based methods can run only the most relevant tests or run tests in a more effective order. This report examines the technical aspects of how Microsoft employs ML for test prioritization in CI – covering model types, features, training data, integration into CI systems, and the resulting efficiency gains.

## Traditional Approaches vs. ML-Based Test Prioritization 
Before diving into ML, it’s worth noting Microsoft’s traditional test selection techniques. **Test Impact Analysis (TIA)** is a feature available in Visual Studio and Azure DevOps that performs **incremental test selection** based on code changes ([Accelerated Continuous Testing with Test Impact Analysis - Part 1 - Azure DevOps Blog](https://devblogs.microsoft.com/devops/accelerated-continuous-testing-with-test-impact-analysis-part-1/#:~:text=sophisticated%20view%20of%20what%20is,only%20report%20the%20relevant%20results)). TIA uses static heuristics (like mapping code areas to tests via prior code coverage) to run “only the relevant tests required to validate that commit” ([Accelerated Continuous Testing with Test Impact Analysis - Part 1 - Azure DevOps Blog](https://devblogs.microsoft.com/devops/accelerated-continuous-testing-with-test-impact-analysis-part-1/#:~:text=sophisticated%20view%20of%20what%20is,only%20report%20the%20relevant%20results)). This built-in tool can be enabled in Azure Pipelines (e.g. by checking *“Run only impacted tests”* in the Visual Studio Test task) to automatically skip tests unaffected by a given commit ([Accelerated Continuous Testing with Test Impact Analysis - Part 1 - Azure DevOps Blog](https://devblogs.microsoft.com/devops/accelerated-continuous-testing-with-test-impact-analysis-part-1/#:~:text=commit%20entering%20the%20pipeline%20TIA,will%20be%20faster%20as%20well)) ([Accelerated Continuous Testing with Test Impact Analysis - Part 1 - Azure DevOps Blog](https://devblogs.microsoft.com/devops/accelerated-continuous-testing-with-test-impact-analysis-part-1/#:~:text=Enabling%20TIA)). Such static analysis-driven approaches improve throughput by avoiding running *all* tests on every build, focusing on those likely impacted by the code diff.

Microsoft has also deployed custom test prioritization systems in the past. For example, the Windows team implemented **CRANE**, a system combining failure prediction, change risk analysis, and test prioritization for Windows Vista maintenance patches ([Microsoft Word - ICST2011_CRANE_CameraReady.docx](https://www.microsoft.com/en-us/research/wp-content/uploads/2011/03/ICST2011_CRANE_CameraReady.pdf#:~:text=on%20the%20use%20of%20these,other%20organizations%20to%20implement%20similar)). CRANE leveraged heuristics like *Echelon*, which compared code differences between builds to rank tests most likely to catch regressions ([Microsoft Word - ICST2011_CRANE_CameraReady.docx](https://www.microsoft.com/en-us/research/wp-content/uploads/2011/03/ICST2011_CRANE_CameraReady.pdf#:~:text=VI,Effective%20test%20selection%20makes%20it)). In practice, running tests in the recommended order helped catch roughly *50–63%* of the bugs with the early subset of tests ([Microsoft Word - ICST2011_CRANE_CameraReady.docx](https://www.microsoft.com/en-us/research/wp-content/uploads/2011/03/ICST2011_CRANE_CameraReady.pdf#:~:text=studies%20suggest%20that%20the%20effectiveness,We%20considered%20a)) ([Microsoft Word - ICST2011_CRANE_CameraReady.docx](https://www.microsoft.com/en-us/research/wp-content/uploads/2011/03/ICST2011_CRANE_CameraReady.pdf#:~:text=Echelon%27s%20effectiveness%20%5BC%2FB%5D%2052,also%20plan%20to%20use%20a)), allowing faster detection of regressions. However, CRANE’s approach was largely rule-based (static analysis and simple predictive models) and the engineers noted it could be improved by incorporating more advanced data-driven techniques ([Microsoft Word - ICST2011_CRANE_CameraReady.docx](https://www.microsoft.com/en-us/research/wp-content/uploads/2011/03/ICST2011_CRANE_CameraReady.pdf#:~:text=Echelon%27s%20effectiveness%20%5BC%2FB%5D%2052,also%20plan%20to%20use%20a)). 

**Limitations of static approaches:** Traditional test selection (like TIA or Echelon) relies on predefined rules (e.g. code coverage mappings or file dependency lists). These methods don’t learn from outcomes – they might still run many tests that *historically always pass* or miss subtle risk factors (like the experience of the coder or the history of a test’s flakiness). This motivates Microsoft’s move towards ML-driven solutions that can **learn patterns from historical data** and adapt over time, going beyond what manual rules capture.

## ML Models and Features for Test Prioritization 
Microsoft’s more recent efforts (notably in large-scale cloud services like Office 365) use machine learning to prioritize or even skip tests based on predictions. A prominent example is **FastLane**, an internal system integrated into Office 365’s CI pipeline that employs several ML-driven components ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=4,Section%20V)). FastLane’s approach is multifaceted, combining multiple models/algorithms:

- **Commit Risk Prediction (“CommRisk”):** This is a classification model that predicts whether a given code commit is *likely safe* (all tests would pass) or *risky* (some test would fail) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=FastLane%20is%20implemented%20and%20integrated,why%20our%20techniques%20work%20in)). If a commit is predicted “safe” with high confidence, the system can **avoid running the full test suite** on that commit, accelerating the pipeline. Microsoft built this model using **historical commit and test outcome data** as training examples. Each commit is labeled based on whether its tests passed or failed, and represented by a rich set of features (in FastLane, **133 features** were used) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=commit,We%20test%20our)). The features are drawn from prior research on defect prediction ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=The%20features%20that%20we%20use,be%20attributed%20at%20component%20or)) and capture numerous aspects of the change, such as: 

  - **Code Churn and Diff Metrics:** e.g. number of files modified, types of files changed, and the magnitude of changes. Certain file types correlate with higher failure risk – for instance, changes to C# source files or XML configs were found far more likely to cause test failures than changes to project files or ini files ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=We%20found%20that%20the%20most,F)). Features also include the history of each file (how often and how recently it was changed over the last 1, 2, and 6 months) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=features%20are%20calculated%20over%20the,developer%20experience%20and%20reviewer%20experience)), since frequent or recent modifications can indicate instability.
  - **Ownership and Author History:** e.g. the number of distinct contributors to the touched files and whether the current author is familiar with those areas. Prior studies at Microsoft showed lack of code ownership correlates with defects ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=happened%20and%20also%20learning%20from,based%20features)). Thus, FastLane includes features for code ownership (files with many past authors vs. a single owner) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=happened%20and%20also%20learning%20from,based%20features)). It also tracks developer experience metrics – for example, whether the commit’s author or reviewers are new to the project or have a history of introducing risky changes ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=features%20are%20calculated%20over%20the,developer%20experience%20and%20reviewer%20experience)).
  - **Other Process Features:** e.g. the code review latency or churn in directories – essentially any measurable signal of risk gleaned from the version control and work item history ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=The%20features%20that%20we%20use,be%20attributed%20at%20component%20or)). All file-level features are aggregated to the commit level (using max, avg, etc.) so the model sees both the biggest risk file and overall patterns ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=commit,We%20test%20our)).

  For the CommRisk model, Microsoft experimented with various ML algorithms and ultimately chose a **decision-tree-based model** (specifically, the **FastTree** gradient-boosted decision tree from ML.NET) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=We%20trained%20our%20model%20using,allows%20us%20to%20reason%20about)). This choice was made because tree models offered high accuracy while also providing interpretability (engineers could inspect which features were driving a “risky” prediction) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=We%20trained%20our%20model%20using,allows%20us%20to%20reason%20about)). The model was trained on thousands of past commits (FastLane used ~16,958 commits from one year as training data) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=commit,We%20test%20our)) and updated regularly as new data arrived. In offline evaluation, the commit risk model achieved an Area Under Curve (AUC) of ~0.84, substantially better than a random predictor ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=in%20Table%20IV,allows%20us%20to%20reason%20about)), meaning it was quite effective at distinguishing risky vs. safe changes. By adjusting the classification threshold, Microsoft can trade off between skipping more tests and being more conservative. For example, one operating point was to skip tests on ~8.7% of commits and still achieve about **89.7% precision** at the commit level (i.e. 89.7% of commits predicted safe were truly safe) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=Fig.%203.%20Safe%20Precision,The%20pass%20precision%20of)). In practice the threshold is set even more strictly – FastLane targets **99%+ precision** to practically never miss a failing commit, which yields a slightly lower fraction of commits skipped (~10% of test time saved) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=Fig.%203.%20Safe%20Precision,The%20pass%20precision%20of)) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=off%20between%20time%20saved%20%2810.38,99)). In other words, only when the model is ~99% confident that all tests would pass does it let a commit bypass running certain tests.

- **Test Outcome Correlation (“TestCorr”):** Instead of focusing on the commit, this technique looks at relationships between tests. Microsoft observed that many tests are **redundant or strongly correlated** – e.g. two tests might always fail together because they exercise the same underlying functionality ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=%E2%80%9Csend%20email%E2%80%9D%20functionality,two%20different%20sets%20of%20developers)). TestCorr analyzes historical test results to find pairs of tests that consistently have the same outcome on the same commit ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=T%20estCorr%20has%20three%20steps,fails%29%20%3D%E2%87%92)). If two tests have run together at least N times (FastLane used pairs that ran ≥50 times) and have an extremely high coincidence of outcomes (FastLane requires >99% of the time they either both pass or both fail together) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=T%20estCorr%20has%20three%20steps,FastLane%20sets%20Ctoc%20to%20the)) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=Test%20B%20passes%20,mining%20algo%02rithms%20such%20as%20Apriori)), then one test is essentially *predictive* of the other. FastLane mines these associations and learns rules like: “If Test A passes, then Test B will also pass” ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=count%20of%20all%20the%20times,seems%20quite%20natural%20to%20find)). During CI, if a commit triggers a pair of correlated tests, the system can choose to **run only one of them** (usually the faster one) and skip the other, implicitly predicting its result ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=match%20at%20L517%20needs%20to,the)). This reduces duplication of effort. Using this data-driven rule mining (akin to association rule learning), Microsoft identified an enormous number of correlated test pairs in the Office 365 test corpus – over **270,000 pairs** of tests with statistically strong outcome correlation ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=Test%20B%20passes%20,mining%20algo%02rithms%20such%20as%20Apriori)). By applying a conservative confidence threshold (99%), they ensure these rules are reliable. The TestCorr mechanism is lightweight (just counting co-failures and co-passes) and effectively prioritizes a subset of tests that represent others. In FastLane’s evaluation, a configuration of TestCorr alone could save on the order of **10% of test execution time** while maintaining **99.95% accuracy** in outcomes ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=T%20estCorr%20RESULTS%20SHOW%20HOW,random)). This means thousands of redundant test executions were eliminated with virtually no missed failures.

- **Runtime-Based Test Prediction ( “RunPred” ):** Microsoft also employs a specialized model to cut short long-running tests when possible. The insight is that for certain tests, the **time taken to fail vs. pass** is characteristically different ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=D.%20Runtime,separation%20between%20failures%20and%20passes)). For example, a complex integration test might *usually fail quickly* (e.g. if a fatal error occurs early) but when it passes, it runs to completion (taking much longer). FastLane uses logistic regression analysis on historical test duration data to find, for each test, a **runtime threshold Δt** that best separates passing vs. failing runs ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=D.%20Runtime,separation%20between%20failures%20and%20passes)). If, during a CI run, a given test exceeds its learned threshold without failing, the system predicts that the test is going to pass and **stops the test early** ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=threshold%20for%20these%20tests,FastLane%20which%20incorporates%20this%20algorithm)) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=second%20test,for%20which%20FastLane%20made%20predictions)). Essentially, if a failure would have occurred, it would have happened before the threshold; so after that point continuing to run is deemed unnecessary. This technique directly saves time on tests that tend to hang or have a long tail runtime when passing. Implementing RunPred requires the CI infrastructure to support **monitoring test execution in real-time and aborting tests** mid-run ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=some%20are%20easier%20to%20apply,practically%20deployed%20in%20their%20environment)). FastLane’s design includes this capability to cancel a test once it hits the time cutoff and record a predicted pass. Not all organizations may have this level of control, so Microsoft notes that RunPred is the most **challenging to deploy** in practice (compared to skipping tests entirely or skipping redundant tests) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=some%20are%20easier%20to%20apply,practically%20deployed%20in%20their%20environment)). Nonetheless, it can yield significant time savings for expensive test cases that rarely fail beyond a certain point.

Each of these components – commit risk prediction, test correlation rules, and runtime thresholding – addresses test prioritization from a different angle. **Training data** for these models came from Microsoft’s rich internal telemetry: version control history and code review data (for commit features), test result databases (for failure correlations), and test run timing logs (for performance patterns). In the Office 365 case study, FastLane trained on *14 months* of data: tens of thousands of commits and millions of test results, totaling many terabytes of log data ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=language,and%20others%20internal%20to%20our)). Training and model updates were automated as part of the pipeline’s data processing: the system periodically retrains models (e.g. the commit risk model was retrained daily with new commits) so that it adapts to evolving code and test behaviors ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=We%20now%20describe%20Step%204,the%20actual%20results%20of%20the)) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=runs%20with%20the%20outcomes%20predicted,test%20run%02time%20and%20also%20the)). Microsoft built FastLane’s ML models using the **ML.NET** framework in C# ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=We%20have%20implemented%20FastLane%20with,We%20implemented%20loaders%20for%20various)) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=We%20have%20implemented%20FastLane%20with,We%20implemented%20loaders%20for%20various)) – a testament to their use of their own tooling (ML.NET is Microsoft’s open-source machine learning library for .NET). The overall implementation of FastLane was ~18,000 lines of C# and SQL code ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=We%20have%20implemented%20FastLane%20with,We%20implemented%20loaders%20for%20various)), reflecting the complexity of integrating data collection, model training, and real-time decision-making.

## Integration into CI Pipelines and Tools 
Integrating ML-driven test prioritization into a CI pipeline requires carefully blending predictions with the normal test execution flow. Microsoft’s approach in FastLane was to insert a decision-making layer *before and during* test execution in the pipeline:

- When a new code commit is submitted to the CI system, the pipeline first invokes the **Commit Risk model**. If the model predicts the commit is **“safe”** with high confidence, FastLane can elect to **run a minimal set of tests or even skip certain test suites entirely** for that commit ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=FastLane%20is%20implemented%20and%20integrated,why%20our%20techniques%20work%20in)). (The exact policy can be configured by the team – e.g. they might still run a small smoke test suite on every commit, but skip the bulk of the long functional tests for predicted-safe changes.) If the commit is predicted **“risky”**, then the pipeline proceeds with the normal set of required tests. In essence, this step triages commits: low-risk changes fast-track through testing, while higher-risk ones get full scrutiny.

- Next, for commits that do need testing (either because they were deemed risky or because some tests are always run regardless), the system applies the **Test Correlation rules** to decide which tests to run. In a traditional run, if X test cases are relevant (based on impacted areas), all X would be queued. Under the ML-augmented system, the pipeline checks if any of those tests have a known correlated partner. If so, it will **run only one test from each highly-correlated pair** ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=match%20at%20L517%20needs%20to,the)). For example, suppose a code change triggers both *TestEntityUpdate* and *TestEntityRepair* (from the earlier example, which always fail or pass together) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=Two%20tests%20may%20be%20redundant,pairs)) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=two%20different%20sets%20of%20developers,ran%20together%20on%20a%20commit)). FastLane might choose to execute only *TestEntityUpdate* (the faster of the two) and skip *TestEntityRepair*, implicitly trusting that the result will be the same. This selection is done up front in the test execution plan, effectively **prioritizing representative tests and deferring redundant ones**.

- As tests are running, the **RunPred logic** comes into play. The pipeline monitors each running test’s execution time. If a test exceeds its learned failure threshold Δt without failing, the system will **terminate the test run** and mark it as passed (predicted) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=second%20test,for%20which%20FastLane%20made%20predictions)). This frees up the test agent machine sooner and allows the pipeline to move on, saving potentially minutes on long tests. Similarly, if a test is approaching a known failure pattern (though typically failures would have already occurred by the threshold), the system could also predict a failure – but the common use is cutting off likely passes to save time.

- **Continuous model validation:** Because ML predictions can sometimes be wrong (or grow stale as code evolves), Microsoft designed the integration to *continuously validate and improve* the models. FastLane includes a background process (off the critical CI path) that will occasionally **run tests that were skipped/predicted** to verify the ML’s decisions ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=We%20now%20describe%20Step%204,the%20actual%20results%20of%20the)) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=in%20the%20background,as%20well%2C%20we%20recognize%20that)). For instance, if the commit risk model skipped a test suite, a fraction of those tests might still be executed asynchronously (not blocking the developer) to confirm they indeed would have passed. If any discrepancy is found (e.g. a test was predicted to pass but actually fails in the background run), the system catches it and can alert engineers or retrain the model with that data. This feedback loop ensures the models remain accurate and adapt to new failure modes or test changes ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=We%20now%20describe%20Step%204,predicted%20by%20the%20models%2C%20FastLane)) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=runs%20with%20the%20outcomes%20predicted,test%20run%02time%20and%20also%20the)). Essentially, the pipeline “learns” over time – similar to how an autonomous system fine-tunes its predictions by occasionally exploring skipped actions. According to Microsoft, FastLane retrains its models daily and continually updates the correlation rules as new test outcomes arrive, making it a living part of the CI infrastructure ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=We%20now%20describe%20Step%204,the%20actual%20results%20of%20the)) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=runs%20with%20the%20outcomes%20predicted,test%20run%02time%20and%20also%20the)).

Integrating such ML logic required custom development in the Office 365 CI system, but Microsoft leveraged standard tools where possible. The choice of ML.NET allowed the models to be hosted within the .NET-based pipeline services ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=We%20have%20implemented%20FastLane%20with,We%20implemented%20loaders%20for%20various)). Data was pulled from existing **“Big Data” test log stores** and version control (e.g. Git) – FastLane had modules to load data from internal source control and work item systems into its ML pipeline ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=language,and%20others%20internal%20to%20our)) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=Since%20FastLane%20requires%20information%20about,and%20others%20internal%20to%20our)). The team also provided “tuning knobs” for service owners to configure the aggressiveness of skipping (for example, adjusting confidence thresholds) so that each product team could balance speed vs. risk to their comfort ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=approaches%20into%20one%20control%20flow,collected%20over%20a%20period%20of)).

Beyond internal systems like FastLane, Microsoft’s developer tools offer extensibility for test optimization. Azure DevOps (AzDO) Pipelines can incorporate custom scripts or extensions, so a team could integrate a similar ML-based test selection step in their YAML pipeline. In fact, third-party services like **Launchable** (not a Microsoft product, but notable in this space) offer ML-driven test selection that can plug into GitHub Actions or AzDO – these work on the same principle of using historical test data to select the most likely-to-fail tests first or drop low-yield tests ([Predictive Test Selection - Launchable](https://www.launchableinc.com/predictive-test-selection/#:~:text=Predictive%20Test%20Selection%20,execution%20times%20%26%20find%20failures)). While not a built-in Azure feature as of 2025, such integrations highlight that Microsoft’s ecosystem is open to AI-driven testing enhancements. Microsoft has also made it easy to incorporate machine learning in DevOps via Azure Machine Learning pipelines or ML.NET model hosting, which teams can use to build bespoke solutions. 

It’s worth noting that the out-of-the-box **Test Impact Analysis** in Azure DevOps remains a readily available tool for basic incremental test runs, and can be seen as a forerunner to these ML methods. TIA doesn’t use ML, but by only running tests impacted by the code changes, it already can significantly shorten CI durations ([Accelerated Continuous Testing with Test Impact Analysis - Part 1 - Azure DevOps Blog](https://devblogs.microsoft.com/devops/accelerated-continuous-testing-with-test-impact-analysis-part-1/#:~:text=sophisticated%20view%20of%20what%20is,only%20report%20the%20relevant%20results)). The ML approaches like FastLane can be seen as **“supercharged” test impact analysis – using data mining and predictive modeling to go further** than static dependencies. In practice, a combination can be used: first limit to impacted tests (TIA), then use ML to prioritize or trim that set even more. Microsoft’s CI pipelines are flexible enough to accommodate these layered optimizations.

## Results and Efficiency Improvements 
Microsoft has reported substantial efficiency gains from using machine learning to prioritize tests in CI. In the Office 365 FastLane deployment, the combined techniques (commit risk classification + correlated test selection + runtime predictions) yielded an overall **18% reduction in test execution time** across the continuous integration pipeline ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=FastLane%20is%20implemented%20and%20integrated,why%20our%20techniques%20work%20in)). This is a significant win: nearly one-fifth of test time shaved off, translating to faster build completions and quicker feedback to developers. Crucially, this time savings was achieved **without sacrificing quality** – FastLane maintained **99.99% accuracy** in predicting test outcomes ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=FastLane%20is%20implemented%20and%20integrated,why%20our%20techniques%20work%20in)), meaning virtually no real bugs were overlooked by skipping tests. In concrete terms, if a full test suite took 5 hours, the ML-driven approach might complete in around 4 hours, with the same confidence in build health. And for extremely large test suites that used to take 30 hours in the worst case, an 18% speedup saves on the order of **5–6 hours** – potentially the difference between getting results in a day versus overnight.

Breaking down the contributions: the commit risk model alone, at a very conservative setting, was able to avoid running tests on ~10% of low-risk changes, directly saving about 8–10% of test time with ~99% confidence (only on rare occasions would a skipped test have failed) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=Fig.%203.%20Safe%20Precision,The%20pass%20precision%20of)) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=off%20between%20time%20saved%20%2810.38,99)). The test correlation approach eliminated hundreds of thousands of redundant test executions, yielding another ~10% time savings at high precision ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=T%20estCorr%20RESULTS%20SHOW%20HOW,random)). And runtime predictions trimmed long test runs, which especially benefits slow end-to-end tests. When combined, these approaches provided a compounding effect (FastLane’s ~18% total gain) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=Table%20VIII%2C%20FastLane%20saves%2018.04,time%20FastLane%20saves%20when%20it)).

From a developer productivity standpoint, these improvements directly reduce **developer wait times** for CI feedback. Instead of waiting half a day for a PR validation to finish, developers get results hours sooner. Faster CI cycles mean issues are identified earlier in the development process, enabling quicker fixes and less context-switching for engineers. Microsoft engineers noted in user studies that the ML-based system helped them “stay in the flow,” since most safe changes get rapid validation and only risky changes trigger long test runs ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=FastLane%20is%20implemented%20and%20integrated,why%20our%20techniques%20work%20in)) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=runs%20with%20the%20outcomes%20predicted,test%20run%02time%20and%20also%20the)). There is also a resource utilization benefit: test machines in the cloud are freed up sooner, allowing parallel jobs to run and increasing overall throughput of the continuous testing infrastructure ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=in%20the%20background,as%20well%2C%20we%20recognize%20that)). Essentially, ML prioritization lets the pipeline do more work with the same resources by not spending time on low-value test executions.

Microsoft’s experience provides a real-world case study of at-scale test optimization. In the Windows division, even the simpler static prioritization (CRANE/Echelon) showed that running a selected subset of tests first could catch over half of the bugs faster ([Microsoft Word - ICST2011_CRANE_CameraReady.docx](https://www.microsoft.com/en-us/research/wp-content/uploads/2011/03/ICST2011_CRANE_CameraReady.pdf#:~:text=studies%20suggest%20that%20the%20effectiveness,We%20considered%20a)), giving developers earlier warning for many regressions. FastLane’s ML-driven approach took this further by intelligently cutting down the test set itself. An illustrative outcome: by focusing on tests most likely to fail, the system ensures that if there *is* a breaking change, it surfaces quickly – and if there isn’t, the developer isn’t kept waiting on dozens of always-passing tests. This aligns with the goal of **“failing faster”** when there’s a real problem, and otherwise finishing the pipeline as fast as possible.

It’s also notable that Microsoft achieved these gains using relatively **lightweight models** (decision trees, simple correlation counts, logistic regression for thresholds) rather than overly complex or deep learning techniques. This was intentional to keep the system interpretable and maintainable ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=We%20trained%20our%20model%20using,allows%20us%20to%20reason%20about)) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=To%20the%20best%20of%20our,to%20other%20services%20as%20well)). Engineers could trust and tune the models (for example, understanding that “changes to XML config files are risky” ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=We%20found%20that%20the%20most,F)) or “commits by new contributors should always run full tests”). The success of these methods has opened the door for more data-driven DevOps practices within Microsoft. We may see future integration of such intelligence directly into Azure DevOps or GitHub Actions offerings, as the industry trend (including at Facebook, Google, etc.) is moving toward predictive test selection ([Predictive Test Selection - Meta Research - Facebook](https://research.facebook.com/publications/predictive-test-selection/#:~:text=We%20propose%20a%20new%20predictive,to%20the%20continuous%20integration%20system)) ([Predictive Test Selection - Launchable](https://www.launchableinc.com/predictive-test-selection/#:~:text=Predictive%20Test%20Selection%20,execution%20times%20%26%20find%20failures)).

## Conclusion 
Microsoft’s use of machine learning for test prioritization in CI pipelines exemplifies how AI can optimize software engineering workflows. By training on extensive historical data – from code changes and ownership to test results and durations – Microsoft builds models that **predict which tests matter the most** for a given code commit. These predictions are seamlessly integrated into CI/CD systems (like Azure DevOps pipelines and internal build systems) to skip or reorder tests, yielding faster build times and quicker feedback. The technical underpinnings include gradient-boosted decision tree classifiers to assess commit risk, association rule mining to find redundant tests, and statistical timing models to cut off tests early. Features feeding these models range from code churn metrics to developer experience signals, drawn from the rich data collected in modern DevOps environments. 

In practice, the ML-driven approach has delivered measurable improvements: significant reduction in test execution load (on the order of 10–20% less tests run) and corresponding reductions in pipeline duration, all while maintaining near-perfect defect detection parity with running all tests. This translates to hours saved per build in large projects and a smoother experience for developers who spend less time waiting on CI results. Microsoft’s investment in such intelligent tooling – from research papers ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=FastLane%20is%20implemented%20and%20integrated,why%20our%20techniques%20work%20in)) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=T%20estCorr%20has%20three%20steps,fails%29%20%3D%E2%87%92)) to internal deployment – highlights the value of prioritizing tests with machine learning. As these techniques mature, we can expect them to be more widely available, possibly integrated into mainstream tools like Visual Studio, Azure DevOps, and GitHub. For now, Microsoft’s engineering teams continue to refine these models, and the lessons learned (e.g. importance of continuous retraining, conservative thresholds, and interpretability) are shaping the future of **smart continuous testing** in the industry.

**Sources:**

- Pratap Lakshman, *“Accelerated Continuous Testing with Test Impact Analysis – Part 1,”* Azure DevOps Blog (2017) ([Accelerated Continuous Testing with Test Impact Analysis - Part 1 - Azure DevOps Blog](https://devblogs.microsoft.com/devops/accelerated-continuous-testing-with-test-impact-analysis-part-1/#:~:text=sophisticated%20view%20of%20what%20is,only%20report%20the%20relevant%20results)) ([Accelerated Continuous Testing with Test Impact Analysis - Part 1 - Azure DevOps Blog](https://devblogs.microsoft.com/devops/accelerated-continuous-testing-with-test-impact-analysis-part-1/#:~:text=commit%20entering%20the%20pipeline%20TIA,will%20be%20faster%20as%20well)).  
- Adithya A. Philip et al., *“FastLane: Test Minimization for Rapidly Deployed Large-scale Online Services,”* Microsoft Research (2019) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=FastLane%20is%20implemented%20and%20integrated,why%20our%20techniques%20work%20in)) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=We%20have%20implemented%20FastLane%20with,We%20implemented%20loaders%20for%20various)).  
- Jacek Czerwonka et al., *“CRANE: Failure Prediction, Change Analysis and Test Prioritization in Practice – Experiences from Windows,”* Microsoft (2011) ([Microsoft Word - ICST2011_CRANE_CameraReady.docx](https://www.microsoft.com/en-us/research/wp-content/uploads/2011/03/ICST2011_CRANE_CameraReady.pdf#:~:text=VI,Effective%20test%20selection%20makes%20it)) ([Microsoft Word - ICST2011_CRANE_CameraReady.docx](https://www.microsoft.com/en-us/research/wp-content/uploads/2011/03/ICST2011_CRANE_CameraReady.pdf#:~:text=studies%20suggest%20that%20the%20effectiveness,We%20considered%20a)).  
- Office 365 CI case study – test statistics and ML outcomes ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=tests%20per%20test,a%20commit%20can%20be%20large)) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=Fig.%203.%20Safe%20Precision,The%20pass%20precision%20of)).  
- FastLane algorithm details – commit risk features and model performance ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=We%20found%20that%20the%20most,F)) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=We%20trained%20our%20model%20using,allows%20us%20to%20reason%20about)); test correlation and runtime prediction methods ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=T%20estCorr%20has%20three%20steps,FastLane%20sets%20Ctoc%20to%20the)) ([](https://www.microsoft.com/en-us/research/uploads/prod/2018/12/PID5783051.pdf#:~:text=D.%20Runtime,separation%20between%20failures%20and%20passes)).